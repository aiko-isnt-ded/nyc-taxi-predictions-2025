{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b43603da",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "\n",
    "# <font color= #8FC3FA> **NYC Taxi Predictions 2025 - Model Experiments 2** </font>\n",
    "#### <font color= #2E9AFE> `Data Science Project - Homework 5`</font>\n",
    "- <Strong> Viviana Toledo </Strong>\n",
    "- <Strong> Fecha: </Strong> 28/10/2025\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31a36f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Databricks Env\n",
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Optimization\n",
    "import math\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# Modeling\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# MLFlow\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "# Autolog function\n",
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "986894f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)  # Carga las variables del archivo .env\n",
    "EXPERIMENT_NAME = \"/Users/viviana.toledo@iteso.mx/nyc-taxi-experiments\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "experiment = mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886ee042",
   "metadata": {},
   "source": [
    "# <font color= #8FC3FA> **1. Data Loading** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d6b07e",
   "metadata": {},
   "source": [
    "First of all, we'll start by loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a6c24d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(path):\n",
    "    df = pd.read_parquet(path)\n",
    "    df[\"duration\"] = (df.lpep_dropoff_datetime - df.lpep_pickup_datetime).dt.total_seconds() / 60\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "    df[[\"PULocationID\", \"DOLocationID\"]] = df[[\"PULocationID\", \"DOLocationID\"]].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f7e7df",
   "metadata": {},
   "source": [
    "The data is stored in .parquet files. Our function defined above helps us handle these types of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ab3e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('../data/green_tripdata_2025-01.parquet')\n",
    "df_val = read_dataframe('../data/green_tripdata_2025-02.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538ad099",
   "metadata": {},
   "source": [
    "For modeling, we create a new variable composed of two variables in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f99abf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"PU_DO\"] = df_train[\"PULocationID\"] + \"_\" + df_train[\"DOLocationID\"]\n",
    "df_val[\"PU_DO\"] = df_val[\"PULocationID\"] + \"_\" + df_val[\"DOLocationID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c15dc53",
   "metadata": {},
   "source": [
    "# <font color= #8FC3FA> **2. Feature Engineering** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40a5517",
   "metadata": {},
   "source": [
    "Afterwards, we will proceed to apply feature engineering, which includes dividing features by categorical and numerical types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64c587d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, dv):\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "    train_dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    return dv.transform(train_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "085ae985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries for preprocessing\n",
    "dv = DictVectorizer()\n",
    "\n",
    "# Define categorical and numerical variables\n",
    "categorical = ['PU_DO']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "# Fit DictVectorizer on training data\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "# Validation\n",
    "X_val = preprocess(df_val, dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a10f63",
   "metadata": {},
   "source": [
    "And our target variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76a2b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac346b2",
   "metadata": {},
   "source": [
    "Upload the datasets to mlflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51907543",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = mlflow.data.from_numpy(X_train.data, targets=y_train, name=\"green_tripdata_2025-01\")\n",
    "validation_dataset = mlflow.data.from_numpy(X_val.data, targets=y_val, name=\"green_tripdata_2025-02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e647a49",
   "metadata": {},
   "source": [
    "# <font color= #8FC3FA> **3. Modeling** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61852e33",
   "metadata": {},
   "source": [
    "## <font color= #8FC3FA> &ensp; • **Random Forest** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de6abcb",
   "metadata": {},
   "source": [
    "We're going to perform a hyperparameter search for our Random Forest Regressor Model using Optuna. Firstly, we have to define the target function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eac843d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Definir la función objetivo para Optuna\n",
    "#    - Recibe un `trial`, que se usa para proponer hiperparámetros.\n",
    "#    - Entrena un modelo con esos hiperparámetros.\n",
    "#    - Calcula la métrica de validación (RMSE) y la retorna (Optuna la minimizará).\n",
    "#    - Abrimos un run anidado de MLflow para registrar cada trial.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    # Hiperparámetros MUESTREADOS por Optuna en CADA trial.\n",
    "    # Nota: usamos log=True para emular rangos log-uniformes (similar a loguniform).\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 30, 150),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 100),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 40, 200),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 4, 100),\n",
    "        \"min_weight_fraction_leaf\": trial.suggest_float(\"min_weight_fraction_leaf\", math.exp(-3), math.exp(-1), log=True),\n",
    "        \"max_features\": trial.suggest_int(\"max_features\", 30, 120),\n",
    "        \"ccp_alpha\": trial.suggest_float(\"ccp_alpha\",   math.exp(-4), math.exp(-3), log=True),\n",
    "        \"random_state\": 42,                      \n",
    "    }\n",
    "\n",
    "    # Run anidado para dejar rastro de cada trial en MLflow\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.set_tag(\"model_family\", \"randomforest\")  # etiqueta informativa\n",
    "        mlflow.log_params(params)                  # registra hiperparámetros del trial\n",
    "\n",
    "        # Entrenamiento con el conjunto de validación\n",
    "        rf = RandomForestRegressor(**params)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # Predicción y métrica en validación\n",
    "        y_pred = rf.predict(X_val)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "        # Registrar la métrica principal\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        # La \"signature\" describe la estructura esperada de entrada y salida del modelo:\n",
    "        # incluye los nombres, tipos y forma (shape) de las variables de entrada y el tipo de salida.\n",
    "        # MLflow la usa para validar datos en inferencia y documentar el modelo en el Model Registry.\n",
    "        signature = infer_signature(X_val, y_pred)\n",
    "\n",
    "        # Guardar el modelo del trial como artefacto en MLflow.\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model = rf,\n",
    "            name=\"model\",\n",
    "            input_example=X_val[:5],\n",
    "            signature=signature,\n",
    "        )\n",
    "\n",
    "    # Optuna minimiza el valor retornado\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b45954c",
   "metadata": {},
   "source": [
    "Now, we can execute the search and log the models into MLFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a83869b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-27 14:22:02,396] A new study created in memory with name: no-name-e379721e-8167-441e-8ed8-5b3092b1840c\n",
      "2025/10/27 14:22:14 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11aa8aae843341b5a96befae108665ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:22:14 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-27 14:22:16,596] Trial 0 finished with value: 9.064385451624798 and parameters: {'n_estimators': 75, 'max_depth': 96, 'min_samples_split': 157, 'min_samples_leaf': 62, 'min_weight_fraction_leaf': 0.06801937287807802, 'max_features': 44, 'ccp_alpha': 0.01941098011269108}. Best is trial 0 with value: 9.064385451624798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run gregarious-hare-167 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/7ac811e95d7b43f1864c880c0f2bd0bd\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:22:30 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc51f3a2b004175953a80b5736961bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:22:30 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run vaunted-lark-735 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/e3fd60c06f064eec9f1bc92d415bb65c\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-27 14:22:34,169] Trial 1 finished with value: 9.06029456412943 and parameters: {'n_estimators': 134, 'max_depth': 62, 'min_samples_split': 153, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.34639335147622574, 'max_features': 105, 'ccp_alpha': 0.0226485173281456}. Best is trial 1 with value: 9.06029456412943.\n",
      "2025/10/27 14:22:47 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60d9c2601a04d1695d919e9028ad769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:22:47 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-27 14:22:49,863] Trial 2 finished with value: 9.045930904269012 and parameters: {'n_estimators': 52, 'max_depth': 21, 'min_samples_split': 88, 'min_samples_leaf': 54, 'min_weight_fraction_leaf': 0.11811341610272008, 'max_features': 56, 'ccp_alpha': 0.03377119342948611}. Best is trial 2 with value: 9.045930904269012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run chill-cod-478 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/de3f430ee62e4eb98950b7a152b3f187\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:23:03 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d515c2cbb6594c18afa56a003988f0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:23:04 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-27 14:23:06,932] Trial 3 finished with value: 9.038064743212965 and parameters: {'n_estimators': 46, 'max_depth': 32, 'min_samples_split': 98, 'min_samples_leaf': 48, 'min_weight_fraction_leaf': 0.23939315532729308, 'max_features': 48, 'ccp_alpha': 0.03063030006982894}. Best is trial 3 with value: 9.038064743212965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run placid-eel-0 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/4340d3f3f4e343e0b99020f1d6201ee1\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:23:20 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce21b17467784cc8acbc2a9b219692c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:23:21 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-27 14:23:23,832] Trial 4 finished with value: 9.044298582129173 and parameters: {'n_estimators': 101, 'max_depth': 8, 'min_samples_split': 137, 'min_samples_leaf': 20, 'min_weight_fraction_leaf': 0.05670477741547259, 'max_features': 116, 'ccp_alpha': 0.04810505725669613}. Best is trial 3 with value: 9.038064743212965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run casual-duck-562 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/8945da67ec164ef6a0741022ed60c8e1\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:23:37 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3146a54f5241cea283d3c6d1f8659b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:23:38 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-27 14:23:40,628] Trial 5 finished with value: 9.081505354360715 and parameters: {'n_estimators': 127, 'max_depth': 33, 'min_samples_split': 55, 'min_samples_leaf': 70, 'min_weight_fraction_leaf': 0.12006824223834135, 'max_features': 41, 'ccp_alpha': 0.030052089392406243}. Best is trial 3 with value: 9.038064743212965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run grandiose-carp-187 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/f94d19cee9034a4698a115d68df8f1a8\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:23:53 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df84c0aca87a447abb3d9ddcd9cab379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:23:53 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-27 14:23:56,218] Trial 6 finished with value: 8.924256539537533 and parameters: {'n_estimators': 34, 'max_depth': 92, 'min_samples_split': 81, 'min_samples_leaf': 68, 'min_weight_fraction_leaf': 0.09286784222526208, 'max_features': 77, 'ccp_alpha': 0.031641373693897024}. Best is trial 6 with value: 8.924256539537533.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run useful-roo-268 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/8a3a893bf8e94550bded0ad33cda18de\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:24:08 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36869595fc2f4b04af4a7867f57209b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:24:09 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run trusting-cat-710 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/66e12afee5474db694626bdc34dd9f80\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-27 14:24:13,188] Trial 7 finished with value: 8.986968973033756 and parameters: {'n_estimators': 52, 'max_depth': 98, 'min_samples_split': 164, 'min_samples_leaf': 95, 'min_weight_fraction_leaf': 0.29809432993955604, 'max_features': 84, 'ccp_alpha': 0.04604547586979493}. Best is trial 6 with value: 8.924256539537533.\n",
      "2025/10/27 14:24:25 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4824517005e84680b303a98a276c5234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:24:26 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-27 14:24:28,908] Trial 8 finished with value: 9.012455083384186 and parameters: {'n_estimators': 40, 'max_depth': 23, 'min_samples_split': 47, 'min_samples_leaf': 35, 'min_weight_fraction_leaf': 0.10832217175080468, 'max_features': 54, 'ccp_alpha': 0.041950602205837094}. Best is trial 6 with value: 8.924256539537533.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run inquisitive-lynx-719 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/3544efdb99c14e3a98a7aa06410e14f8\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:24:41 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47bc6a31ab043a8be578ea20cb743d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:24:41 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-27 14:24:44,318] Trial 9 finished with value: 9.063312967428525 and parameters: {'n_estimators': 73, 'max_depth': 31, 'min_samples_split': 127, 'min_samples_leaf': 17, 'min_weight_fraction_leaf': 0.24768288551081558, 'max_features': 36, 'ccp_alpha': 0.049138469238622876}. Best is trial 6 with value: 8.924256539537533.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run nebulous-koi-698 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/9eccf9aad50849fb8f51ccc0c2320e8a\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:24:57 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597accdddaa54d76a2a670fbc3f89468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vivienne\\apps\\data_science_project\\nyc-taxi-predictions-2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "2025/10/27 14:25:00 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run RandomForest Hyperparameter Optimization (Optuna) at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/ba151bbef11e4745be891e8ace7eec39\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    }
   ],
   "source": [
    "mlflow.sklearn.autolog(log_models=False)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Crear el estudio de Optuna\n",
    "#    - Usamos TPE (Tree-structured Parzen Estimator) como sampler.\n",
    "#    - direction=\"minimize\" porque queremos minimizar el RMSE.\n",
    "# ------------------------------------------------------------\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Ejecutar la optimización (n_trials = número de intentos)\n",
    "#    - Cada trial ejecuta la función objetivo con un set distinto de hiperparámetros.\n",
    "#    - Abrimos un run \"padre\" para agrupar toda la búsqueda.\n",
    "# ------------------------------------------------------------\n",
    "with mlflow.start_run(run_name=\"RandomForest Hyperparameter Optimization (Optuna)\", nested=True):\n",
    "    study.optimize(objective, n_trials=10)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Recuperar y registrar los mejores hiperparámetros\n",
    "    # --------------------------------------------------------\n",
    "    best_params = study.best_params\n",
    "    # Asegurar tipos/campos fijos (por claridad y consistencia)\n",
    "    best_params[\"max_depth\"] = int(best_params[\"max_depth\"])\n",
    "    best_params[\"seed\"] = 42\n",
    "    best_params[\"objective\"] = \"reg:squarederror\"\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Etiquetas del run \"padre\" (metadatos del experimento)\n",
    "    mlflow.set_tags({\n",
    "        \"project\": \"NYC Taxi Time Prediction Project\",\n",
    "        \"optimizer_engine\": \"optuna\",\n",
    "        \"model_family\": \"randomforest\",\n",
    "        \"feature_set_version\": 1,\n",
    "    })\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 7) Entrenar un modelo FINAL con los mejores hiperparámetros\n",
    "    #    (normalmente se haría sobre train+val o con CV; aquí mantenemos el patrón original)\n",
    "    # --------------------------------------------------------\n",
    "\n",
    "    # Select parameters\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=best_params[\"n_estimators\"],\n",
    "        max_depth=best_params[\"max_depth\"],\n",
    "        min_samples_split=best_params[\"min_samples_split\"],\n",
    "        min_samples_leaf=best_params[\"min_samples_leaf\"],\n",
    "        min_weight_fraction_leaf=best_params[\"min_weight_fraction_leaf\"],\n",
    "        max_features=best_params[\"max_features\"],\n",
    "        ccp_alpha=best_params[\"ccp_alpha\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    # Fit the model\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluar y registrar la métrica final en validación\n",
    "    y_pred = rf.predict(X_val)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 8) Guardar artefactos adicionales (p. ej. el preprocesador)\n",
    "    # --------------------------------------------------------\n",
    "    pathlib.Path(\"preprocessor\").mkdir(exist_ok=True)\n",
    "    with open(\"preprocessor/preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "\n",
    "    mlflow.log_artifact(\"preprocessor/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "    # La \"signature\" describe la estructura esperada de entrada y salida del modelo:\n",
    "    # incluye los nombres, tipos y forma (shape) de las variables de entrada y el tipo de salida.\n",
    "    # MLflow la usa para validar datos en inferencia y documentar el modelo en el Model Registry.\n",
    "    # Si X_val es la matriz dispersa (scipy.sparse) salida de DictVectorizer:\n",
    "    feature_names = dv.get_feature_names_out()\n",
    "    input_example = pd.DataFrame(X_val[:5].toarray(), columns=feature_names)\n",
    "\n",
    "    # Para que las longitudes coincidan, usa el mismo slice en y_pred\n",
    "    signature = infer_signature(input_example, y_val[:5])\n",
    "\n",
    "    # Guardar el modelo del trial como artefacto en MLflow.\n",
    "    mlflow.sklearn.log_model(\n",
    "    sk_model=rf,                    # Trained RandomForestRegressor\n",
    "    name=\"model\",                   # Folder inside MLflow run to store the model\n",
    "    input_example= input_example,   # First few rows of validation data\n",
    "    signature=signature,            \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f4d01c",
   "metadata": {},
   "source": [
    "## <font color= #8FC3FA> &ensp; • **Gradient Boosting** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83610590",
   "metadata": {},
   "source": [
    "Same procedure, we're going to define a hyperparameter search using Optuna for Gradient Boosting's hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a495f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Definir la función objetivo para Optuna\n",
    "#    - Recibe un `trial`, que se usa para proponer hiperparámetros.\n",
    "#    - Entrena un modelo con esos hiperparámetros.\n",
    "#    - Calcula la métrica de validación (RMSE) y la retorna (Optuna la minimizará).\n",
    "#    - Abrimos un run anidado de MLflow para registrar cada trial.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    # Hiperparámetros MUESTREADOS por Optuna en CADA trial.\n",
    "    # Nota: usamos log=True para emular rangos log-uniformes (similar a loguniform).\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", math.exp(-2), math.exp(2), log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 250),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 100),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 30, 150),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 4, 100),\n",
    "        \"min_weight_fraction_leaf\": trial.suggest_float(\"min_weight_fraction_leaf\", math.exp(-3), math.exp(-1), log=True),\n",
    "        \"max_features\": trial.suggest_int(\"max_features\", 20, 150),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\",   math.exp(-4), math.exp(-3), log=True),\n",
    "        \"random_state\": 42,                      \n",
    "    }\n",
    "\n",
    "    # Run anidado para dejar rastro de cada trial en MLflow\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.set_tag(\"model_family\", \"randomforest\")  # etiqueta informativa\n",
    "        mlflow.log_params(params)                  # registra hiperparámetros del trial\n",
    "\n",
    "        # Entrenamiento con el conjunto de validación\n",
    "        rf = GradientBoostingRegressor(**params)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # Predicción y métrica en validación\n",
    "        y_pred = rf.predict(X_val)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "        # Registrar la métrica principal\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        # La \"signature\" describe la estructura esperada de entrada y salida del modelo:\n",
    "        # incluye los nombres, tipos y forma (shape) de las variables de entrada y el tipo de salida.\n",
    "        # MLflow la usa para validar datos en inferencia y documentar el modelo en el Model Registry.\n",
    "        signature = infer_signature(X_val, y_pred)\n",
    "\n",
    "        # Guardar el modelo del trial como artefacto en MLflow.\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model = rf,\n",
    "            name=\"model\",\n",
    "            input_example=X_val[:5],\n",
    "            signature=signature,\n",
    "        )\n",
    "\n",
    "    # Optuna minimiza el valor retornado\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25b92b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-27 14:11:36,758] A new study created in memory with name: no-name-a251830a-8e32-47ef-9525-4b724ce0d6dc\n",
      "2025/10/27 14:11:51 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad98a81274094f6aa67743bae53094d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:11:51 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run judicious-steed-9 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/2963be72564b49118cce5377a098fdea\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-27 14:11:54,159] Trial 0 finished with value: 6.888353263797699 and parameters: {'learning_rate': 0.88047001533197, 'n_estimators': 241, 'max_depth': 75, 'min_samples_split': 102, 'min_samples_leaf': 19, 'min_weight_fraction_leaf': 0.06801609168822177, 'max_features': 27, 'alpha': 0.043550945979794295}. Best is trial 0 with value: 6.888353263797699.\n",
      "2025/10/27 14:12:06 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5579d59d3d4b56863d15ed3db83fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:12:07 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-27 14:12:09,639] Trial 1 finished with value: 2.299739626174814e+16 and parameters: {'learning_rate': 2.7334787317118483, 'n_estimators': 192, 'max_depth': 5, 'min_samples_split': 147, 'min_samples_leaf': 84, 'min_weight_fraction_leaf': 0.07612932206693435, 'max_features': 43, 'alpha': 0.022002581531949287}. Best is trial 0 with value: 6.888353263797699.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run unleashed-lamb-685 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/df7528e8bcba4c92aeac5c7b12b02c5d\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:12:21 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2282ec96374b4dbfb5cec1bb34d476f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:12:21 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-27 14:12:24,062] Trial 2 finished with value: 6.769214040737485 and parameters: {'learning_rate': 0.6195333254805603, 'n_estimators': 155, 'max_depth': 45, 'min_samples_split': 65, 'min_samples_leaf': 63, 'min_weight_fraction_leaf': 0.06580810455571189, 'max_features': 58, 'alpha': 0.02641988964868964}. Best is trial 2 with value: 6.769214040737485.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run intrigued-boar-845 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/76aad694056343149eccc6f3d5f68c83\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:12:49 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2556bfa66a5340a5be24699102b5ee04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:12:50 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-27 14:12:52,270] Trial 3 finished with value: 6.555500839641166 and parameters: {'learning_rate': 1.3235928843718132, 'n_estimators': 207, 'max_depth': 23, 'min_samples_split': 92, 'min_samples_leaf': 61, 'min_weight_fraction_leaf': 0.05463398387490681, 'max_features': 99, 'alpha': 0.021720997136040116}. Best is trial 3 with value: 6.555500839641166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run nebulous-ram-486 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/a7d64bad3b764d60aca14ef4c3673550\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:13:04 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79de6dd9bd444eee921de06c19361698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:13:05 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-27 14:13:07,807] Trial 4 finished with value: 7.113998564404653 and parameters: {'learning_rate': 0.18735650465552267, 'n_estimators': 240, 'max_depth': 97, 'min_samples_split': 127, 'min_samples_leaf': 33, 'min_weight_fraction_leaf': 0.060527602883403635, 'max_features': 109, 'alpha': 0.02844316178759491}. Best is trial 3 with value: 6.555500839641166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run invincible-slug-118 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/547883e7b2f349178081f2125c7a509e\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:13:19 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2fed3a9ac94be1b36fd7f26668e7a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:13:20 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-27 14:13:22,659] Trial 5 finished with value: 7.8904944717239625 and parameters: {'learning_rate': 0.24912292596156269, 'n_estimators': 149, 'max_depth': 7, 'min_samples_split': 140, 'min_samples_leaf': 29, 'min_weight_fraction_leaf': 0.18731652775154203, 'max_features': 60, 'alpha': 0.03080950666040755}. Best is trial 3 with value: 6.555500839641166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run blushing-dove-921 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/0e66de584c58408f90a2d5213424a5b5\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:13:35 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b769a9e79ec451f94ba9eb3acccaf03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:13:35 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run exultant-worm-631 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/3e75320f4dc644f7b3f514d827486cb1\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-27 14:13:38,196] Trial 6 finished with value: 9.048138062076204 and parameters: {'learning_rate': 2.082463143527972, 'n_estimators': 87, 'max_depth': 98, 'min_samples_split': 123, 'min_samples_leaf': 95, 'min_weight_fraction_leaf': 0.29809432993955604, 'max_features': 98, 'alpha': 0.04604547586979493}. Best is trial 3 with value: 6.555500839641166.\n",
      "2025/10/27 14:13:50 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc32b70ac854a468ec6b1e96c859abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:13:50 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-27 14:13:53,147] Trial 7 finished with value: 8.484712081400259 and parameters: {'learning_rate': 0.21065417108333506, 'n_estimators': 89, 'max_depth': 8, 'min_samples_split': 69, 'min_samples_leaf': 41, 'min_weight_fraction_leaf': 0.0856657711379556, 'max_features': 128, 'alpha': 0.02616724939319006}. Best is trial 3 with value: 6.555500839641166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run glamorous-snail-444 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/4b6d4197105b4f81b6ac719a65f8e87a\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:14:05 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6df2f1e6974a43a331219cab69be57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:14:06 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-27 14:14:08,637] Trial 8 finished with value: 7.145556647867208 and parameters: {'learning_rate': 0.551381985410781, 'n_estimators': 159, 'max_depth': 17, 'min_samples_split': 127, 'min_samples_leaf': 11, 'min_weight_fraction_leaf': 0.35835680503910405, 'max_features': 121, 'alpha': 0.02234205910288227}. Best is trial 3 with value: 6.555500839641166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run polite-calf-868 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/136a78a84eb14185ac510e57e0b91d77\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:14:21 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e6aff3a04540b2b1880b1955f3bf2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:14:21 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-10-27 14:14:24,172] Trial 9 finished with value: 8.04890174188964 and parameters: {'learning_rate': 0.13912403378084792, 'n_estimators': 213, 'max_depth': 72, 'min_samples_split': 118, 'min_samples_leaf': 78, 'min_weight_fraction_leaf': 0.05773390345224298, 'max_features': 66, 'alpha': 0.020565693809507044}. Best is trial 3 with value: 6.555500839641166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run fearless-loon-617 at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/9b7efb419e6e4b6bb728727ce5a2c534\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:14:37 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d16ffa454a49ceb86eba0819df370f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vivienne\\apps\\data_science_project\\nyc-taxi-predictions-2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "2025/10/27 14:14:40 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run GradientBoosting Hyperparameter Optimization (Optuna) at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792/runs/7bf182f0bf014c6499f50d5787c0570d\n",
      "🧪 View experiment at: https://dbc-ce601eea-1bde.cloud.databricks.com/ml/experiments/2243674360324792\n"
     ]
    }
   ],
   "source": [
    "mlflow.sklearn.autolog(log_models=False)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Crear el estudio de Optuna\n",
    "#    - Usamos TPE (Tree-structured Parzen Estimator) como sampler.\n",
    "#    - direction=\"minimize\" porque queremos minimizar el RMSE.\n",
    "# ------------------------------------------------------------\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Ejecutar la optimización (n_trials = número de intentos)\n",
    "#    - Cada trial ejecuta la función objetivo con un set distinto de hiperparámetros.\n",
    "#    - Abrimos un run \"padre\" para agrupar toda la búsqueda.\n",
    "# ------------------------------------------------------------\n",
    "with mlflow.start_run(run_name=\"GradientBoosting Hyperparameter Optimization (Optuna)\", nested=True):\n",
    "    study.optimize(objective, n_trials=10)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Recuperar y registrar los mejores hiperparámetros\n",
    "    # --------------------------------------------------------\n",
    "    best_params = study.best_params\n",
    "    # Asegurar tipos/campos fijos (por claridad y consistencia)\n",
    "    best_params[\"max_depth\"] = int(best_params[\"max_depth\"])\n",
    "    best_params[\"seed\"] = 42\n",
    "    best_params[\"objective\"] = \"reg:squarederror\"\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Etiquetas del run \"padre\" (metadatos del experimento)\n",
    "    mlflow.set_tags({\n",
    "        \"project\": \"NYC Taxi Time Prediction Project\",\n",
    "        \"optimizer_engine\": \"optuna\",\n",
    "        \"model_family\": \"gradientboosting\",\n",
    "        \"feature_set_version\": 1,\n",
    "    })\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 7) Entrenar un modelo FINAL con los mejores hiperparámetros\n",
    "    #    (normalmente se haría sobre train+val o con CV; aquí mantenemos el patrón original)\n",
    "    # --------------------------------------------------------\n",
    "\n",
    "    # Select parameters\n",
    "    gb = GradientBoostingRegressor(\n",
    "        learning_rate=best_params[\"learning_rate\"],\n",
    "        n_estimators=best_params[\"n_estimators\"],\n",
    "        max_depth=best_params[\"max_depth\"],\n",
    "        min_samples_split=best_params[\"min_samples_split\"],\n",
    "        min_samples_leaf=best_params[\"min_samples_leaf\"],\n",
    "        min_weight_fraction_leaf=best_params[\"min_weight_fraction_leaf\"],\n",
    "        max_features=best_params[\"max_features\"],\n",
    "        alpha=best_params[\"alpha\"],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    gb.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluar y registrar la métrica final en validación\n",
    "    y_pred = gb.predict(X_val)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 8) Guardar artefactos adicionales (p. ej. el preprocesador)\n",
    "    # --------------------------------------------------------\n",
    "    pathlib.Path(\"preprocessor\").mkdir(exist_ok=True)\n",
    "    with open(\"preprocessor/preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "\n",
    "    mlflow.log_artifact(\"preprocessor/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "    # La \"signature\" describe la estructura esperada de entrada y salida del modelo:\n",
    "    # incluye los nombres, tipos y forma (shape) de las variables de entrada y el tipo de salida.\n",
    "    # MLflow la usa para validar datos en inferencia y documentar el modelo en el Model Registry.\n",
    "    # Si X_val es la matriz dispersa (scipy.sparse) salida de DictVectorizer:\n",
    "    feature_names = dv.get_feature_names_out()\n",
    "    input_example = pd.DataFrame(X_val[:5].toarray(), columns=feature_names)\n",
    "\n",
    "    # Para que las longitudes coincidan, usa el mismo slice en y_pred\n",
    "    signature = infer_signature(input_example, y_val[:5])\n",
    "\n",
    "    # Guardar el modelo del trial como artefacto en MLflow.\n",
    "    mlflow.sklearn.log_model(\n",
    "    sk_model=gb,                    # Trained GradientBoostingRegressor\n",
    "    name=\"model\",                   # Folder inside MLflow run to store the model\n",
    "    input_example= input_example,   # First few rows of validation data\n",
    "    signature=signature,            \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38abb7fb",
   "metadata": {},
   "source": [
    "# <font color= #8FC3FA> **4. Model Evaluation** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42ad028",
   "metadata": {},
   "source": [
    "For the experiments we previously ran, our objective is to determine a new challenger model to run against our champion model, which was an XGBoost. For this, we're going to use the metric validation-rmse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1cdcba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Challenger Run:\n",
      "Run ID: 8f3b81a764e740ed888c21f24dfaa625\n",
      "Model Type: None\n",
      "RMSE: 6.416337650057929\n",
      "Params: {'alpha': '0.021720997136040116', 'ccp_alpha': '0.0', 'criterion': 'friedman_mse', 'init': 'None', 'learning_rate': '0.8388527762909672', 'loss': 'squared_error', 'max_depth': '23', 'max_features': '99', 'max_leaf_nodes': 'None', 'min_impurity_decrease': '0.0', 'min_samples_leaf': '61', 'min_samples_split': '92', 'min_weight_fraction_leaf': '0.05463398387490681', 'n_estimators': '207', 'n_iter_no_change': 'None', 'objective': 'reg:squarederror', 'random_state': '42', 'seed': '42', 'subsample': '1.0', 'tol': '0.0001', 'validation_fraction': '0.1', 'verbose': '0', 'warm_start': 'False'}\n"
     ]
    }
   ],
   "source": [
    "runs = mlflow.search_runs(\n",
    "    experiment_names=[EXPERIMENT_NAME],\n",
    "    order_by=[\"metrics.rmse ASC\"],\n",
    "    output_format=\"list\"\n",
    ")\n",
    "\n",
    "# Filter for only RandomForest or GradientBoosting models \n",
    "challenger_runs = []\n",
    "for run in runs:\n",
    "    run_name = run.info.run_name\n",
    "    if run_name and any(model_type in run_name for model_type in ['RandomForest', 'GradientBoosting']):\n",
    "        challenger_runs.append(run)\n",
    "\n",
    "# Get the best run \n",
    "if len(challenger_runs) > 0:\n",
    "    best_run = challenger_runs[0]\n",
    "    print(\"Found Challenger Run:\")\n",
    "    print(f\"Run ID: {best_run.info.run_id}\")\n",
    "    print(f\"Model Type: {best_run.data.params.get('model_type')}\")\n",
    "    print(f\"RMSE: {best_run.data.metrics['rmse']}\")\n",
    "    print(f\"Params: {best_run.data.params}\")\n",
    "else:\n",
    "    print(\"⚠️ No RandomForest or GradientBoosting runs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25771c0b",
   "metadata": {},
   "source": [
    "The best model was a GradientBoosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e1bc8b",
   "metadata": {},
   "source": [
    "# <font color= #8FC3FA> **5. MLFlow Registering** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b97d7",
   "metadata": {},
   "source": [
    "Now, we have to register the best model to MLFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39895fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'workspace.default.nyc-taxi-model' already exists. Creating a new version of this model...\n",
      "2025/10/27 16:34:29 WARNING mlflow.tracking._model_registry.fluent: Run with id 8f3b81a764e740ed888c21f24dfaa625 has no artifacts at artifact path 'model', registering model based on models:/m-d073db763a764b59b1c93c337bd31e5a instead\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7d6d949891472b94bdbc4d28a44091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e336af310d24630bc544391b2c0d90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '5' of model 'workspace.default.nyc-taxi-model'.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"workspace.default.nyc-taxi-model\"\n",
    "\n",
    "run_id = input(\"Ingrese el run_id\")\n",
    "run_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "result = mlflow.register_model(\n",
    "    model_uri=f\"runs:/{best_run.info.run_id}/model\",\n",
    "    name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61f5af5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "\n",
    "model_version = result.version\n",
    "new_alias = \"Challenger\"\n",
    "\n",
    "client.set_registered_model_alias(\n",
    "    name=model_name,\n",
    "    alias=new_alias,\n",
    "    version=result.version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8170c932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1761604475852, current_stage=None, deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description=('The model version 5 was transitioned to Challenger on 2025-10-27 '\n",
       " '16:35:51.787841'), last_updated_timestamp=1761604552513, metrics=[<Metric: dataset_digest='', dataset_name='', key='rmse', model_id='m-d073db763a764b59b1c93c337bd31e5a', run_id='8f3b81a764e740ed888c21f24dfaa625', step=0, timestamp=1761595560358, value=6.416337650057929>,\n",
       " <Metric: dataset_digest='', dataset_name='', key='training_mean_absolute_error', model_id='m-d073db763a764b59b1c93c337bd31e5a', run_id='8f3b81a764e740ed888c21f24dfaa625', step=0, timestamp=1761595556742, value=4.091565974350377>,\n",
       " <Metric: dataset_digest='', dataset_name='', key='training_mean_squared_error', model_id='m-d073db763a764b59b1c93c337bd31e5a', run_id='8f3b81a764e740ed888c21f24dfaa625', step=0, timestamp=1761595556742, value=36.82599599454175>,\n",
       " <Metric: dataset_digest='', dataset_name='', key='training_r2_score', model_id='m-d073db763a764b59b1c93c337bd31e5a', run_id='8f3b81a764e740ed888c21f24dfaa625', step=0, timestamp=1761595556742, value=0.5052642316910427>,\n",
       " <Metric: dataset_digest='', dataset_name='', key='training_root_mean_squared_error', model_id='m-d073db763a764b59b1c93c337bd31e5a', run_id='8f3b81a764e740ed888c21f24dfaa625', step=0, timestamp=1761595556742, value=6.068442633373224>,\n",
       " <Metric: dataset_digest='', dataset_name='', key='training_score', model_id='m-d073db763a764b59b1c93c337bd31e5a', run_id='8f3b81a764e740ed888c21f24dfaa625', step=0, timestamp=1761595556773, value=0.5052642316910427>], model_id='m-d073db763a764b59b1c93c337bd31e5a', name='workspace.default.nyc-taxi-model', params=[<LoggedModelParameter: key='tol', value='0.0001'>,\n",
       " <LoggedModelParameter: key='max_leaf_nodes', value='None'>,\n",
       " <LoggedModelParameter: key='ccp_alpha', value='0.0'>,\n",
       " <LoggedModelParameter: key='verbose', value='0'>,\n",
       " <LoggedModelParameter: key='warm_start', value='False'>,\n",
       " <LoggedModelParameter: key='loss', value='squared_error'>,\n",
       " <LoggedModelParameter: key='max_features', value='99'>,\n",
       " <LoggedModelParameter: key='subsample', value='1.0'>,\n",
       " <LoggedModelParameter: key='random_state', value='42'>,\n",
       " <LoggedModelParameter: key='init', value='None'>,\n",
       " <LoggedModelParameter: key='validation_fraction', value='0.1'>,\n",
       " <LoggedModelParameter: key='seed', value='42'>,\n",
       " <LoggedModelParameter: key='criterion', value='friedman_mse'>,\n",
       " <LoggedModelParameter: key='min_samples_leaf', value='61'>,\n",
       " <LoggedModelParameter: key='learning_rate', value='0.8388527762909672'>,\n",
       " <LoggedModelParameter: key='n_estimators', value='207'>,\n",
       " <LoggedModelParameter: key='n_iter_no_change', value='None'>,\n",
       " <LoggedModelParameter: key='min_samples_split', value='92'>,\n",
       " <LoggedModelParameter: key='objective', value='reg:squarederror'>,\n",
       " <LoggedModelParameter: key='min_weight_fraction_leaf', value='0.05463398387490681'>,\n",
       " <LoggedModelParameter: key='max_depth', value='23'>,\n",
       " <LoggedModelParameter: key='min_impurity_decrease', value='0.0'>,\n",
       " <LoggedModelParameter: key='alpha', value='0.021720997136040116'>], run_id='8f3b81a764e740ed888c21f24dfaa625', run_link=None, source='models:/m-d073db763a764b59b1c93c337bd31e5a', status='READY', status_message='', tags={}, user_id='viviana.toledo@iteso.mx', version='5'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = datetime.today()\n",
    "\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    description=f\"The model version {model_version} was transitioned to {new_alias} on {date}\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nyc-taxi-predictions-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
